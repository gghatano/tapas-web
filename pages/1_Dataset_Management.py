import streamlit as st
import pandas as pd
import json
import os
import sys
from pathlib import Path

# TAPASãƒ‘ã‚¹ã®è¿½åŠ 
tapas_path = Path(__file__).parent.parent / "tapas"
if str(tapas_path) not in sys.path:
    sys.path.insert(0, str(tapas_path))

st.set_page_config(
    page_title="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç† - TAPAS",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†")
st.write("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è©•ä¾¡ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»ç®¡ç†ã—ã¾ã™ã€‚")

# ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
DATA_DIR = Path("data/uploaded")
DATA_DIR.mkdir(parents=True, exist_ok=True)

# TAPASã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
tapas_available = False
try:
    import tapas.datasets
    tapas_available = True
except ImportError as e:
    st.error(f"TAPASãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£ã—ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“: {e}")
    tapas_available = False

# ã‚¿ãƒ–ä½œæˆ
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§", "ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°"])

with tab1:
    st.header("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["csv"],
        help="ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è©•ä¾¡ã‚’è¡Œã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’CSVå½¢å¼ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚"
    )
    
    if uploaded_file is not None:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        st.write("### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** {uploaded_file.name}")
            st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** {uploaded_file.size / 1024:.1f} KB")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã®å…¥åŠ›
        with col2:
            dataset_name = st.text_input(
                "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå",
                value=uploaded_file.name.replace(".csv", ""),
                help="ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åå‰ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        try:
            df = pd.read_csv(uploaded_file)
            st.write("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(10))
            
            # ãƒ‡ãƒ¼ã‚¿æƒ…å ±
            st.write("### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è¡Œæ•°", len(df))
            with col2:
                st.metric("åˆ—æ•°", len(df.columns))
            with col3:
                st.metric("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡", f"{df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            
            # åˆ—æƒ…å ±
            with st.expander("åˆ—ã®è©³ç´°æƒ…å ±", expanded=False):
                col_info = pd.DataFrame({
                    "ãƒ‡ãƒ¼ã‚¿å‹": df.dtypes,
                    "éNULLæ•°": df.count(),
                    "NULLæ•°": df.isnull().sum(),
                    "ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°": df.nunique()
                })
                st.dataframe(col_info)
            
            # ä¿å­˜ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            st.write("### ä¿å­˜ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
            col1, col2 = st.columns(2)
            
            with col1:
                description = st.text_area(
                    "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜",
                    help="ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
                )
            
            with col2:
                st.write("**TAPASå½¢å¼ã¸ã®å¤‰æ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³**")
                if tapas_available:
                    convert_to_tapas = st.checkbox(
                        "TAPASå½¢å¼ã«å¤‰æ›ã—ã¦ä¿å­˜",
                        value=True,
                        help="TAPASãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ä½¿ç”¨å¯èƒ½ãªå½¢å¼ã«å¤‰æ›ã—ã¾ã™ã€‚"
                    )
                else:
                    st.warning("TAPASãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€CSVå½¢å¼ã®ã¿ã§ä¿å­˜ã•ã‚Œã¾ã™ã€‚")
                    convert_to_tapas = False
            
            # ä¿å­˜ãƒœã‚¿ãƒ³
            if st.button("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¿å­˜", type="primary"):
                try:
                    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
                    dataset_dir = DATA_DIR / dataset_name
                    dataset_dir.mkdir(exist_ok=True)
                    
                    csv_path = dataset_dir / f"{dataset_name}.csv"
                    df.to_csv(csv_path, index=False)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                    metadata = {
                        "name": dataset_name,
                        "description": description,
                        "original_filename": uploaded_file.name,
                        "rows": len(df),
                        "columns": len(df.columns),
                        "column_names": df.columns.tolist(),
                        "dtypes": df.dtypes.astype(str).to_dict(),
                        "upload_date": pd.Timestamp.now().isoformat()
                    }
                    
                    metadata_path = dataset_dir / "metadata.json"
                    with open(metadata_path, "w") as f:
                        json.dump(metadata, f, indent=2)
                    
                    # TAPASå½¢å¼ã§ã®ä¿å­˜
                    if convert_to_tapas and tapas_available:
                        try:
                            # TAPASãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜ã‚’ä½œæˆ
                            columns = []
                            for col in df.columns:
                                dtype = str(df[col].dtype)
                                if dtype.startswith('int'):
                                    col_type = 'Integer'
                                elif dtype.startswith('float'):
                                    col_type = 'Continuous'
                                else:
                                    col_type = 'Categorical'
                                
                                columns.append({
                                    "name": col,
                                    "type": col_type
                                })
                            
                            description_data = {
                                "columns": columns
                            }
                            
                            # TAPASç”¨ã®è¨˜è¿°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                            description_path = dataset_dir / f"{dataset_name}.json"
                            with open(description_path, "w") as f:
                                json.dump(description_data, f, indent=2)
                            
                            st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ãŒæ­£å¸¸ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")
                            st.info("TAPASå½¢å¼ã§ã®ä¿å­˜ã‚‚å®Œäº†ã—ã¾ã—ãŸã€‚")
                        except Exception as e:
                            st.warning(f"TAPASå½¢å¼ã¸ã®å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                            st.info("CSVå½¢å¼ã§ã®ä¿å­˜ã¯å®Œäº†ã—ã¦ã„ã¾ã™ã€‚")
                    else:
                        st.success(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{dataset_name}' ãŒæ­£å¸¸ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")
                    
                    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚»ãƒƒãƒˆ
                    uploaded_file = None
                    
                except Exception as e:
                    st.error(f"ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    
        except Exception as e:
            st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

with tab2:
    st.header("ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§")
    
    # ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å–å¾—
    datasets = []
    if DATA_DIR.exists():
        for dataset_dir in DATA_DIR.iterdir():
            if dataset_dir.is_dir():
                metadata_path = dataset_dir / "metadata.json"
                if metadata_path.exists():
                    with open(metadata_path) as f:
                        metadata = json.load(f)
                        datasets.append(metadata)
    
    if datasets:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸€è¦§è¡¨ç¤º
        df_datasets = pd.DataFrame(datasets)
        
        # é¸æŠå¯èƒ½ãªåˆ—ã®ã¿ã‚’è¡¨ç¤º
        display_columns = ["name", "description", "rows", "columns", "upload_date"]
        available_columns = [col for col in display_columns if col in df_datasets.columns]
        
        if available_columns:
            st.dataframe(
                df_datasets[available_columns],
                hide_index=True,
                use_container_width=True
            )
        else:
            st.write("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã®è¡¨ç¤ºãŒã§ãã¾ã›ã‚“ã€‚")
    else:
        st.info("ä¿å­˜æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab3:
    st.header("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°")
    
    if datasets:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
        dataset_names = [d["name"] for d in datasets]
        selected_dataset = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠ", dataset_names)
        
        if selected_dataset:
            # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æƒ…å ±ã‚’å–å¾—
            dataset_info = next(d for d in datasets if d["name"] == selected_dataset)
            dataset_dir = DATA_DIR / selected_dataset
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.write("### ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå:** {dataset_info['name']}")
                st.write(f"**èª¬æ˜:** {dataset_info.get('description', 'ãªã—')}")
                st.write(f"**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ—¥æ™‚:** {dataset_info.get('upload_date', 'ä¸æ˜')}")
            
            with col2:
                st.write(f"**è¡Œæ•°:** {dataset_info.get('rows', 'ä¸æ˜')}")
                st.write(f"**åˆ—æ•°:** {dataset_info.get('columns', 'ä¸æ˜')}")
                st.write(f"**å…ƒãƒ•ã‚¡ã‚¤ãƒ«å:** {dataset_info.get('original_filename', 'ä¸æ˜')}")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            csv_path = dataset_dir / f"{selected_dataset}.csv"
            if csv_path.exists():
                df = pd.read_csv(csv_path)
                
                st.write("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(df.head(20))
                
                # åŸºæœ¬çµ±è¨ˆé‡
                st.write("### åŸºæœ¬çµ±è¨ˆé‡")
                st.dataframe(df.describe())
                
                # ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                st.write("### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç®¡ç†")
                if st.button("ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‰Šé™¤", type="secondary"):
                    confirm = st.checkbox("æœ¬å½“ã«å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚")
                    if confirm:
                        if st.button("å‰Šé™¤ã‚’å®Ÿè¡Œ", type="primary"):
                            try:
                                import shutil
                                shutil.rmtree(dataset_dir)
                                st.success(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ '{selected_dataset}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                                st.experimental_rerun()
                            except Exception as e:
                                st.error(f"å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("ä¿å­˜æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
